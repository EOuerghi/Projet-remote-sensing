{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup code for the notebook\n",
    "\n",
    "%matplotlib notebook \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt      \n",
    "import rasterio       \n",
    "import tsd            \n",
    "import utils         \n",
    "import vistools     \n",
    "import mvalab\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy import ndimage\n",
    "from shapely.geometry import shape, Polygon\n",
    "from pyproj import Proj\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from registration import fft_shift, hanning_win\n",
    "from scipy import ndimage\n",
    "import glob\n",
    "\n",
    "cmap = plt.cm.jet\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix d'un aoi et calcul de son aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# enter manually aoi \n",
    "aoi = {'coordinates': [[(-64.59876276763663, -9.52084640253337), \n",
    "                        (-64.45702835936353, -9.52084640253337), \n",
    "                        (-64.45702835936353, -9.793349040517846), \n",
    "                        (-64.63963938244376, -9.793349040517846), \n",
    "                        (-64.7314453125, -9.752370139173285), \n",
    "                        (-64.59876276763663, -9.52084640253337)]], 'type': 'Polygon'}\n",
    "\n",
    "\n",
    "'''\n",
    "# or use a .geojson file\n",
    "\n",
    "with open('map.geojson') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "aoi = data['features'][0]['geometry']\n",
    "print(aoi)\n",
    "\n",
    "'''\n",
    "\n",
    "def area(aoi):\n",
    "    \"\"\" calculates area in m^2 of a given aoi\"\"\"\n",
    "    lon, lat = zip(*aoi['coordinates'][0])\n",
    "    pa = Proj(\"+proj=aea +lat_1=37.0 +lat_2=41.0 +lat_0=39.0 +lon_0=-106.55\")\n",
    "\n",
    "    x, y = pa(lon, lat)\n",
    "    cop = {\"type\": \"Polygon\", \"coordinates\": [zip(x, y)]}\n",
    "    \n",
    "    return(shape(cop).area)\n",
    "\n",
    "print(area(aoi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suivi de déforestation avec Sentinel-2 : calcul du NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index NDVI et calcul de l'aire forestière sur une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_equalization_8bit(im, percentiles=5):\n",
    "    ''' \n",
    "    im is a numpy array\n",
    "    returns a numpy array\n",
    "    '''\n",
    "    import numpy as np\n",
    "    a, b = np.percentile(im, percentiles), np.percentile(im, 100 - percentiles)\n",
    "    out = np.clip(im, a, b)\n",
    "    out = np.round((out - a) / (b - a) * 255).astype(int)\n",
    "    return out \n",
    "\n",
    "\n",
    "def get_sentinel2_NDVI(geotiff_path_B04, geotiff_path_B08):\n",
    "    ''' \n",
    "    geotiff_path_B04 : path to band B04\n",
    "    geotiff_path_B08 : path to band B08\n",
    "    \n",
    "    writes *NDVI.tif and returns NDVI numpy array\n",
    "    '''\n",
    "    out = []\n",
    "    im = utils.readGTIFF(geotiff_path_B08)\n",
    "    out.append(im)\n",
    "    im = utils.readGTIFF(geotiff_path_B04)\n",
    "    out.append(im)\n",
    "\n",
    "    NDVI = (out[0] - out[1]) / (out[0] + out[1])  # (NIR - RED)/(NIR + RED)\n",
    "    norm = plt.Normalize(vmin=NDVI.min(), vmax=NDVI.max())\n",
    "    utils.writeGTIFF(NDVI, geotiff_path_B04[:-7] + 'NDVI.tif', geotiff_path_B04)\n",
    "    \n",
    "    return NDVI   \n",
    "\n",
    "\n",
    "def get_sentinel2_RGB(geotiff_path_B02, geotiff_path_B03, geotiff_path_B04, percentiles=5):\n",
    "    ''' \n",
    "    geotiff_path_B02 : path to band B02\n",
    "    geotiff_path_B03 : path to band B03\n",
    "    geotiff_path_B04 : path to band B04\n",
    "    \n",
    "    Returns RGB numpy array\n",
    "    '''\n",
    "    \n",
    "    B04 = utils.readGTIFF(geotiff_path_B04)\n",
    "    B04 = simple_equalization_8bit(B04, percentiles)\n",
    "    B03 = utils.readGTIFF(geotiff_path_B03)\n",
    "    B03 = simple_equalization_8bit(B03, percentiles)\n",
    "    B02 = utils.readGTIFF(geotiff_path_B02)\n",
    "    B02 = simple_equalization_8bit(B02, percentiles)\n",
    "    \n",
    "    out = [B04, B03, B02]\n",
    "    im = np.squeeze(out,axis=(3))\n",
    "    \n",
    "    return im\n",
    "\n",
    "\n",
    "def forest_area(geotiff_path, aoi, s=0.72):\n",
    "    \"\"\"\n",
    "    geotiff_path : path to image\n",
    "    aoi : the aoi corresponding to the image\n",
    "    s : threshold\n",
    "    \n",
    "    Computes the surface of forest in km^2 in the given image.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_surface = area(aoi)\n",
    "    im = utils.readGTIFF(geotiff_path)\n",
    "    vegetal = np.sum((im >= s))\n",
    "    percentage = vegetal / (im.shape[0] * im.shape[1]) # number between 0 and 1\n",
    "\n",
    "    return(percentage * total_surface / 10**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essayons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On télécharge deux images : une en juin 2018, une en juin 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_1 = datetime(2018, 6, 24)\n",
    "end_date_1 = datetime(2018, 7, 1)\n",
    "\n",
    "start_date_2 = datetime(2019, 6, 23)\n",
    "end_date_2 = datetime(2019, 6, 26)\n",
    "\n",
    "directory = './Sentinel-2/test/'\n",
    "\n",
    "tsd.get_sentinel2.get_time_series(aoi, start_date_1, end_date_1, bands=[\"B04\", \"B08\"],  out_dir= directory, api='scihub' )\n",
    "tsd.get_sentinel2.get_time_series(aoi, start_date_2, end_date_2, bands=[\"B04\", \"B08\"],  out_dir=directory, api='scihub'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trie les images par dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geotiff_paths_B04 = glob.glob(directory +'*B04.tif') \n",
    "geotiff_paths_B04.sort(key=(lambda k: (utils.acquisition_date(k))))\n",
    "\n",
    "geotiff_paths_B08 = glob.glob(directory +'*B08.tif') \n",
    "geotiff_paths_B08.sort(key=(lambda k: (utils.acquisition_date(k))))\n",
    "\n",
    "print('{} images found'.format(len(geotiff_paths_B04)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule les NDVI, on les enregistre dans le même repertoire et on les affiche dans une map couleur. Si vous voulez les visualiser en couleur naturelle, décommentez la ligne #vistools.display_gallery(NDVI_list, titres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j in range(len(geotiff_paths_B08)):\n",
    "    out = get_sentinel2_NDVI(geotiff_paths_B04[j], geotiff_paths_B08[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geotiff_paths_NDVI = glob.glob(directory +'*NDVI.tif') \n",
    "geotiff_paths_NDVI.sort(key=(lambda k: (utils.acquisition_date(k))))\n",
    "\n",
    "NDVI_list = []\n",
    "titres = []\n",
    "for geotiff_path in geotiff_paths_NDVI:\n",
    "    \n",
    "    im = utils.readGTIFF(geotiff_path)  \n",
    "    NDVI_list.append(simple_equalization_8bit(im))\n",
    "    titres.append(utils.acquisition_date(geotiff_path))\n",
    "    \n",
    "#vistools.display_gallery(NDVI_list, titres)\n",
    "vistools.display_imshow(utils.readGTIFF(geotiff_paths_NDVI[0]), cmap='jet')\n",
    "vistools.display_imshow(utils.readGTIFF(geotiff_paths_NDVI[1]),cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même si la déforestation est assez claire, on peut la visualiser mieux sur l'image suivante : le pixels blancs sont des pixels pour lesquels le NDVI est passé d'une valeur supérieur à $s$ à une valeur inférieure à $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.72\n",
    "a = 0.3\n",
    "NDVI_1 = utils.readGTIFF(geotiff_paths_NDVI[0])\n",
    "NDVI_2 = utils.readGTIFF(geotiff_paths_NDVI[1])\n",
    "\n",
    "delta_NDVI = NDVI_1 * (NDVI_1 > s) - NDVI_2 * (NDVI_2 > s)\n",
    "delta_NDVI = delta_NDVI * (delta_NDVI > a) + (1 - delta_NDVI) * (delta_NDVI > a)\n",
    "\n",
    "im = utils.simple_equalization_8bit(delta_NDVI,1)\n",
    "vistools.display_imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule enfin la surface forestière aux deux dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for geotiff_path in geotiff_paths_NDVI:\n",
    "    print(\"date :\", utils.acquisition_date(geotiff_path)) \n",
    "    print(\"aire forestiere en km^2 :\", forest_area(geotiff_path, aoi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut généraliser le calcul du NDVI à toute la région Rondônia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe est le suivant :\n",
    "    \n",
    "- On délimite la Rondônia par un polygone aoi_rondonia.\n",
    "- Une centaine de polygones carrés vont recouvrir le aoi_rondonia : on calcule lon_max, lon_min, lat_max, lat_min de l'aoi_rondonia. \n",
    "- On passe ensuite en coordonnées utm via la fonction utils.lonlat_aoi_from_utm_bounding_box.\n",
    "- On peut maintenant crée des polygones carrés de surface $50\\times 50$ km$^2$. On prend leur intersection avec aoi_rondonia.\n",
    "\n",
    "On calcule finalement l'aire déforestée sur chacun des polygones puis on somme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, on met en place tous les polygones qu'on affiche ensuite sur une carte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('rondonia.geojson') as f:\n",
    "    data = json.load(f)\n",
    "aoi_rondonia = data['features'][0]['geometry']\n",
    "\n",
    "e_min, e_max, n_min, n_max, espg = utils.utm_bounding_box_from_lonlat_aoi(aoi_rondonia)\n",
    "size_aoi = 50*1e3 # 50 km \n",
    "\n",
    "m = vistools.clickablemap(zoom=13)\n",
    "footprint = aoi_rondonia\n",
    "m.add_GeoJSON(footprint)\n",
    "m.center = footprint[ 'coordinates'][0][0][::-1]\n",
    "\n",
    "liste_e = np.arange(e_min, e_max, size_aoi)\n",
    "liste_n = np.arange(n_min, n_max, size_aoi)\n",
    "\n",
    "count = 0\n",
    "\n",
    "liste_aoi = []\n",
    "for e in liste_e :\n",
    "    for n in liste_n :\n",
    "        aoi_current = utils.lonlat_aoi_from_utm_bounding_box(e, e + size_aoi, n, n + size_aoi, espg)\n",
    "        \n",
    "        if Polygon(aoi_current[ 'coordinates'][0]).intersects(Polygon(aoi_rondonia[ 'coordinates'][0]))==False:\n",
    "            continue\n",
    "        polygon_intersection = Polygon(aoi_current[ 'coordinates'][0]).intersection(Polygon(aoi_rondonia[ 'coordinates'][0]))\n",
    "        \n",
    "        if polygon_intersection.type == 'MultiPolygon':\n",
    "            for poly in list(polygon_intersection):\n",
    "                liste_aoi.append({'coordinates': [list(poly.exterior.coords)], 'type': 'Polygon'})\n",
    "                m.add_GeoJSON({'coordinates': [list(poly.exterior.coords)], 'type': 'Polygon'})\n",
    "        \n",
    "        else :\n",
    "            aoi_current = {'coordinates': [list(polygon_intersection.exterior.coords)], 'type': 'Polygon'}\n",
    "            liste_aoi.append(aoi_current)\n",
    "            m.add_GeoJSON(aoi_current)\n",
    "        \n",
    "        count +=1\n",
    "        print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, on calcule l'aire déforestée. NE PAS EXECUTER car cela demande le téléchargement de beaucoup d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "foret_debut = 0\n",
    "foret_fin = 0\n",
    "aire_totale = 0\n",
    "\n",
    "for aoi_current in liste_aoi :\n",
    "    if count >= 2: \n",
    "        break\n",
    "        \n",
    "    directory='./Sentinel-2/Rondonia/'+ 'aoi_{}/'.format(count)\n",
    "    \n",
    "    try :\n",
    "        tsd.get_sentinel2.get_time_series(aoi_current, start_date_1, end_date_1, bands=[\"B04\", \"B08\"],  out_dir= directory, api='scihub' )\n",
    "        tsd.get_sentinel2.get_time_series(aoi_current, start_date_2, end_date_2, bands=[\"B04\", \"B08\"],  out_dir=directory,api='scihub'  )\n",
    "\n",
    "        geotiff_paths_B04 = glob.glob(directory + '*B04.tif')\n",
    "        geotiff_paths_B04.sort(key=(lambda k: (utils.acquisition_date(k)))) \n",
    "\n",
    "        geotiff_paths_B08 = glob.glob(directory +'*B08.tif') \n",
    "        geotiff_paths_B08.sort(key=(lambda k: (utils.acquisition_date(k)))) \n",
    "\n",
    "        for j in range(len(geotiff_paths_B08)):\n",
    "            get_sentinel2_NDVI(geotiff_paths_B04[j], geotiff_paths_B08[j])\n",
    "        \n",
    "        geotiff_paths_NDVI = glob.glob(directory + '*NDVI.tif')\n",
    "        geotiff_paths_NDVI.sort(key=(lambda k: (utils.acquisition_date(k)))) \n",
    "\n",
    "        print(\"aoi numéro\", count)\n",
    "        print(\"aire tot\", area(aoi_current)/1e6)\n",
    "        print(\"aire forestière début\", forest_area(geotiff_paths_NDVI[0], aoi_current))\n",
    "        print(\"aire forestière fin\", forest_area(geotiff_paths_NDVI[1], aoi_current))\n",
    "        foret_debut += forest_area(geotiff_paths_NDVI[0], aoi_current)\n",
    "        foret_fin += forest_area(geotiff_paths_NDVI[1], aoi_current)\n",
    "        aire_totale += area(aoi_current)/1e6\n",
    "        count += 1\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Une erreur s'est produite. Il se peut qu'aucune image n'ait été trouvée pour l'AOI. On passe à l'AOI suivant.\")\n",
    "        \n",
    "        count += 1\n",
    "        continue\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarque sur le seuil du NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis le début, on a pris le seuil $s = 0.72$. Justifions ici cette valeur en faisant une simple SVM à partir de l'image NDVI ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory='./Sentinel-2/banque'\n",
    "NDVI = utils.readGTIFF(directory + '2019-06-23_S2B_orbit_096_tile_20LLQ_L1C_band_NDVI.tif')\n",
    "vistools.display_imshow(NDVI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constitue le dataset à partir de pixels de l'image, on calcul le modèle puis on évalue l'accuracy à partir d'un test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "labels = []\n",
    "\n",
    "# classe 1\n",
    "echantillons = list(NDVI[820:920, 480:580].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.ones(len(echantillons))))\n",
    "\n",
    "echantillons = list(NDVI[1120:1200, 1420:1500].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.ones(len(echantillons))))\n",
    "\n",
    "# classe 2\n",
    "echantillons = list(NDVI[1650:1730, 380:460].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.zeros(len(echantillons))))\n",
    "\n",
    "echantillons = list(NDVI[980:1100, 120:220].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.zeros(len(echantillons))))\n",
    "\n",
    "points = np.array([item for sublist in points for item in sublist]).reshape(-1, 1)\n",
    "labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "print(\"Le dataset contient {} echantillons\".format(len(points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(points, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[0.723], [0.724]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux d'accuracy\n",
    "\n",
    "# on crée le test set\n",
    "points = []\n",
    "labels = []\n",
    "\n",
    "# classe 1\n",
    "echantillons = list(NDVI[180:280, 640:740].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.ones(len(echantillons))))\n",
    "\n",
    "echantillons = list(NDVI[1360:1440, 220:300].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.ones(len(echantillons))))\n",
    "\n",
    "echantillons = list(NDVI[1700:1800, 1700:1800].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.ones(len(echantillons))))\n",
    "\n",
    "# classe 2\n",
    "echantillons = list(NDVI[1720:1840, 1360:1500].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.zeros(len(echantillons))))\n",
    "\n",
    "echantillons = list(NDVI[480:580, 20:140].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.zeros(len(echantillons))))\n",
    "\n",
    "echantillons = list(NDVI[1490:1515, 1720:1770].flatten())\n",
    "points.append(echantillons)\n",
    "labels.append(list(np.zeros(len(echantillons))))\n",
    "\n",
    "points = np.array([item for sublist in points for item in sublist]).reshape(-1, 1)\n",
    "labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "erreur = 0\n",
    "for (point, label) in zip(points, labels):\n",
    "    if clf.predict([point]) != label :\n",
    "        erreur += 1\n",
    "                    \n",
    "print(\"Accuracy is : {:4.2f} %\".format((len(points) - erreur) / len(points) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suivi de déforestation avec Sentinel-1 : SAR Shadows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette partie, nous avons choisi l'aoi suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = {'coordinates': [[[-62.19305556, -9.60500000], \n",
    "                        [-62.24972222,-9.85861111], \n",
    "                        [-62.08750000,-9.89500000],\n",
    "                        [-62.03083333,-9.64138889], \n",
    "                        [-62.19305556, -9.60500000]]],'type': 'Polygon'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et nous avons téléchargé des images Sentinel-1 en polarisation vv pour cet AOI entre juin 2017 et juin 2019 avec tsd. Les images sont :\n",
    "2017-06-09_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2017-06-21_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2018-06-16_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2018-06-28_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2018-07-10_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2018-07-22_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2018-08-03_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2018-09-08_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-01-06_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-01-18_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-02-11_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-02-23_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-03-19_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-03-31_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-04-12_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-04-24_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-05-06_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-05-12_S1B_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-05-18_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-05-24_S1B_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-05-30_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-06-05_S1B_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-06-11_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-06-17_S1B_orbit_083_GRD_vv.tif\n",
    "\n",
    "2019-06-23_S1A_orbit_083_GRD_vv.tif\n",
    "\n",
    "On les a placées dans le dossier './Sentinel-1/'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques fonctions requises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabola_refine(c):\n",
    "    '''\n",
    "    maximum of parabolic interpolation \n",
    "    interpolate a parabola through the points \n",
    "    (-1,c[0]), (0,c[1]), (1,c[2]) \n",
    "    assuming that c[1]  >  c[0], c[2]\n",
    "    \n",
    "    I. E. Abdou, \n",
    "    \"Practical approach to the registration of multiple frames of video images\"\n",
    "    Proceedings of Visual Communications and Image Processing '99; (1998); \n",
    "    doi: 10.1117/12.334685\n",
    "    '''\n",
    "    return (c[2]-c[0])/(2*(2*c[1]-c[0]-c[2]))\n",
    "\n",
    "\n",
    "def crosscorrelation(a,b):\n",
    "    '''\n",
    "    returns the cross-correlation of a and b\n",
    "        F^{-1} (F(a) * F(b)^*)\n",
    "    '''\n",
    "\n",
    "    if not (a.shape == b.shape):\n",
    "        print ('ERROR: images not the same size')\n",
    "        return 0,0\n",
    "\n",
    "    sz = a.shape\n",
    "\n",
    "    fa = np.fft.fft2(a)\n",
    "    fb = np.fft.fft2(b)\n",
    "\n",
    "    corrF = fa * np.conj(fb)\n",
    "\n",
    "    corr = np.abs(np.fft.ifft2 ( corrF ))\n",
    "    \n",
    "    return corr\n",
    "    \n",
    "    \n",
    "def max_correlation(a,b):\n",
    "    '''\n",
    "    computes the cross correlation of a and b and uses it \n",
    "    to compute and return (dx,dy) the subpixel shift between a and b \n",
    "    '''\n",
    "\n",
    "    sz = a.shape\n",
    "\n",
    "    corr = crosscorrelation(a,b) \n",
    "  \n",
    "    # improve the interpolability of the maximum by filtering it\n",
    "    corr = np.fft.ifftshift(\n",
    "             scipy.ndimage.filters.gaussian_filter(\n",
    "               np.fft.fftshift(corr),2))\n",
    "    \n",
    "    # position of the maximum \n",
    "    my, mx = np.unravel_index(np.argmax(corr.flatten()), corr.shape) \n",
    "\n",
    "    # subpixel refinement of the maximum\n",
    "    dx = parabola_refine( corr[my, (mx+np.arange(-1,2))% sz[1]] )\n",
    "    dy = parabola_refine( corr[(my+np.arange(-1,2))% sz[0], mx] )\n",
    "\n",
    "    # determine the integer part of the displacement\n",
    "    if mx > sz[1]/2:\n",
    "        mx = mx - sz[1] \n",
    "    if my > sz[0]/2:\n",
    "        my = my - sz[0] \n",
    "\n",
    "    return mx+dx, my+dy\n",
    "\n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et traitement des images\n",
    "On charge toutes les images dans le dossier sentinel1 et on les recale par max correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalage(imgs):\n",
    "    '''\n",
    "    Cette fonction prend en entrée une liste d'images de même taille et \n",
    "    recale toutes les images par maximum de corrélation par rapport à la première\n",
    "    '''\n",
    "    recal = []\n",
    "    a = imgs[0]\n",
    "    recal.append(a)\n",
    "    for im in imgs[1:]:\n",
    "        mx, my = max_correlation(a,im)\n",
    "        b = fft_shift(im,mx,my)\n",
    "        recal.append(b)\n",
    "    return recal\n",
    "\n",
    "\n",
    "A = 531.9922169781931 # Coefficient de calibration moyen pour la zone consité\n",
    "# Sur des crops de taille raisonnable on peut supposer que le coefficient de calibration est constant\n",
    "\n",
    "def gamma_bckscatt(imgs):\n",
    "    '''\n",
    "    Calcule le coefficient de rétropropagation gamma_0\n",
    "    '''\n",
    "    gammas = []\n",
    "    for im in imgs:\n",
    "        gam = 10*np.log10(abs(im)**2/A**2)\n",
    "        gammas.append(gam)\n",
    "    return gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_changes(gamma_list,tau):\n",
    "    '''\n",
    "    Etant donné une liste d'images de backscatter gamma_0 et un threshold tau, \n",
    "    on repère quand est ce qu'on a un phénomène de deforestation\n",
    "    '''\n",
    "    n = len(gamma_list)\n",
    "    tab_RCR = []\n",
    "    change_times = [] # dates des changements\n",
    "    change_loc = [] # position des changements\n",
    "    for t in range(2,n-2):\n",
    "        # Mb = (gamma_list[t]+gamma_list[t-1]+gamma_list[t-2])/3\n",
    "        Mb = np.mean([gamma_list[t],gamma_list[t-1],gamma_list[t-2]],axis =0)\n",
    "        # Ma = (gamma_list[t+1]+gamma_list[t+2])/2\n",
    "        Ma = np.mean([gamma_list[t+1],gamma_list[t+2]], axis = 0)\n",
    "        RCR = Ma - Mb\n",
    "        if np.sum(RCR<tau)>1:\n",
    "            change_times.append(t)\n",
    "            loc = np.argwhere(RCR<tau)\n",
    "            change_loc.append(loc)\n",
    "            tab_RCR.append(RCR)\n",
    "    return change_times, change_loc, tab_RCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On load les images.\n",
    "imgs = []\n",
    "for i in sorted(glob.glob('./Sentinel-1/*_GRD_vv.tif')):\n",
    "    imgs.append( utils.readGTIFF( i )[:,:,0].squeeze() )\n",
    "\n",
    "for im in imgs:\n",
    "    print(im.shape)\n",
    "# On vérifie que toutes les images téléchargées sont de même taille (ce n'est pas toujours le cas)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pré-traitement des images : on les recale et on calcule le coefficient de rétropropagation gamma\n",
    "\n",
    "imgs = recalage(imgs)\n",
    "imgs = gamma_bckscatt(imgs)\n",
    "vistools.display_gallery([ utils.simple_equalization_8bit(x,1) for x in imgs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = -6.5\n",
    "times, loc , rcr = check_changes(imgs,tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve souvent de la déforestation entre toutes les observations. En effet, on observe sur une zone très grande\n",
    "et qui subit énormément de déforestation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On compare l'évolution du coefficient gamma entre une zone avec et sans sar shadows\n",
    "\n",
    "\n",
    "shadow = np.zeros(len(imgs))\n",
    "classic = np.zeros(len(imgs))\n",
    "for k in range(1,len(imgs)-1):\n",
    "    shadow[k] = (imgs[k][260,484]+imgs[k+1][260,484])/2\n",
    "    classic[k] = (imgs[k-1][497,1210]+imgs[k][497,1210])/2\n",
    "    \n",
    "plt.figure(1)\n",
    "plt.plot(shadow[1:len(imgs)-1], label = \"SAR shadow\")\n",
    "plt.plot(classic[1:len(imgs)-1], label = \"Non déforesté\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deforest_near(tab_rcr):\n",
    "    '''\n",
    "    Cette fonction cherche les diminutions de gamma autour des points où il y a des SAR shadows \n",
    "    Elle retourne la carte de déforestation où tous les points déforestés entre la date de debut et de fin sont affichés.\n",
    "    '''\n",
    "    init = tab_rcr[0]\n",
    "    n,m = init.shape\n",
    "    defo = (init<-7)\n",
    "    \n",
    "    for l in range(len(tab_rcr)):\n",
    "        delta = tab_rcr[l]\n",
    "        shadow = np.argwhere(delta<-6)\n",
    "        \n",
    "        for k in range(len(shadow)):\n",
    "            \n",
    "            for i in range(4):\n",
    "                \n",
    "                for j in range(4):\n",
    "                    if (shadow[k][0]+i<n):\n",
    "                        a = shadow[k][0]+i\n",
    "                        if (shadow[k][1]+j<m):\n",
    "                            b = shadow[k][1]+j\n",
    "                            defo[a,b] = 1*(delta[a,b]<-3.1)\n",
    "                        if (shadow[k][1]-j>=0):\n",
    "                            b = shadow[k][1]-j\n",
    "                            defo[a,b] = 1*(delta[a,b]<-3.1)\n",
    "                    if (shadow[k][0]-i>=0):\n",
    "                        a = shadow[k][0]-i\n",
    "                        if (shadow[k][1]+j<m):\n",
    "                            b = shadow[k][1]+j\n",
    "                            defo[a,b] = 1*(delta[a,b]<-3.1)\n",
    "                        if (shadow[k][1]-j>=0):\n",
    "                            b = shadow[k][1]-j\n",
    "                            defo[a,b] = 1*(delta[a,b]<-3.1)\n",
    "                                       \n",
    "    return defo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On observe les changements entre 2017-2018 et 2018-2019\n",
    "\n",
    "rcr1 = ((imgs[0]+imgs[1])/2-((imgs[2]+imgs[3])/2))\n",
    "rcr2 = ((imgs[2]+imgs[3])/2-((imgs[22]+imgs[23])/2))\n",
    "rcr = [rcr1,rcr2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defo = deforest_near(rcr) #carte de déforestation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.writeGTIFF(defo, 'defo.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vistools.display_image(simple_equalization_8bit(defo,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_denoising(defo):\n",
    "    '''\n",
    "    On débruite naïvement la carte de déforestation\n",
    "    Si un pixel labellisé comme déforesté est isolé on considère que c'est du bruit \n",
    "    '''\n",
    "    n,m = defo.shape\n",
    "    for i in range(1,n-1):\n",
    "        for j in range(1,m-1):\n",
    "            if defo[i,j]==1:\n",
    "                if (defo[i,j+1]+defo[i-1,j]+defo[i+1,j]+defo[i,j-1])==0:\n",
    "                    defo[i,j]=0\n",
    "    return defo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defo = naive_denoising(defo)\n",
    "utils.writeGTIFF(defo, 'defo.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vistools.display_image(simple_equalization_8bit(defo,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couplage des deux méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, on compare la carte de déforestation obtenue avec Sentinel-1 juste au dessus, avec celle qu'on obtient avec Sentinel-2. On commence par calculer la carte de disparité pour Sentinel-2 pour l'aoi en question, entre juin 2017 et juin 2019.\n",
    "\n",
    "Les deux images Sentinel-2 choisie sont : \n",
    "\n",
    "2017-06-15_S2A_orbit_053_tile_20LNQ_L1C_band_NDVI.tif\n",
    "\n",
    "2019-06-20_S2B_orbit_053_tile_20LNQ_L1C_band_NDVI.tif\n",
    "\n",
    "On affiche ensuite la superposition de deux aire trouvée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debruitage(im, r=9, s=10, niter=3):\n",
    "    \"\"\" \n",
    "    Pour débruiter une carte de déforestation. Les pixels isolés sont enlevés.\n",
    "    \"\"\"\n",
    "    A = np.copy(im)\n",
    "    for k in range(niter):\n",
    "        for i in range(r,delta_NDVI.shape[0]-r):\n",
    "            for j in range(r,delta_NDVI.shape[1]-r):\n",
    "                if np.sum(delta_NDVI[i-int(r/2): i+int(r/2)+1, j-int(r/2):j+int(r/2)+1]) <= s:\n",
    "                    A[i,j] = 0\n",
    "                    \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='./Sentinel-2/banque/'\n",
    "\n",
    "s = 0.72\n",
    "a = 0.3\n",
    "NDVI_1 = utils.readGTIFF(directory + '2019-06-20_S2B_orbit_053_tile_20LNQ_L1C_band_NDVI.tif')\n",
    "NDVI_2 = utils.readGTIFF(directory + '2017-06-15_S2A_orbit_053_tile_20LNQ_L1C_band_NDVI.tif')\n",
    "\n",
    "delta_NDVI = NDVI_2 * (NDVI_2 > s) - NDVI_1 * (NDVI_1 > s)\n",
    "delta_NDVI = delta_NDVI * (delta_NDVI > a) + (1 - delta_NDVI) * (delta_NDVI > a)\n",
    "delta_NDVI = debruitage(delta_NDVI)\n",
    "\n",
    "delta_GAMMA = utils.readGTIFF(directory + 'DeltaGamma.tif')\n",
    "images = [utils.simple_equalization_8bit(delta_NDVI,1), utils.simple_equalization_8bit(delta_GAMMA,1)]\n",
    "\n",
    "A = np.array([utils.simple_equalization_8bit(delta_NDVI,1),utils.simple_equalization_8bit(delta_GAMMA,1), delta_GAMMA*0])\n",
    "vistools.display_image(A)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule enfin l'aire totale, l'aire en rouge, l'aire en vert, et l'union vert-rouge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aire_tot = area(aoi)\n",
    "print(\"Aire totale:\", aire_tot)\n",
    "\n",
    "# aire Sentinel-1\n",
    "A_1 = np.sum(delta_GAMMA)/(delta_GAMMA.shape[0]*delta_GAMMA.shape[1]) * aire_tot\n",
    "print(\"Aire verte :\", A_1)\n",
    "\n",
    "# aire Sentinel-2\n",
    "A_2 = np.sum(delta_NDVI)/(delta_NDVI.shape[0]*delta_NDVI.shape[1]) * aire_tot\n",
    "print(\"Aire rouge :\", A_2)\n",
    "\n",
    "# aire couplée (union vert-rouge)\n",
    "A_3 = 0\n",
    "for i in range(delta_NDVI.shape[0]):\n",
    "    for j in range(delta_NDVI.shape[1]):\n",
    "        if delta_GAMMA[i,j] == 1 or delta_NDVI[i,j] == 1 :\n",
    "            A_3 += 1\n",
    "A_3 = np.sum(A_3)/(delta_NDVI.shape[0]*delta_NDVI.shape[1]) * aire_tot\n",
    "print(\"Aire union :\", A_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
